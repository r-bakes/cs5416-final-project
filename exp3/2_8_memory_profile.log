[CONFIG] GPU not available, using CPU
============================================================
MICROSERVICES ORCHESTRATOR
============================================================
Orchestrator Node: 0
Port: 9000

Service URLs:
	Embedding (2 instances): ['http://132.236.91.185:9001', 'http://132.236.91.185:9002']
	FAISS (2 instances): ['http://132.236.91.186:8007', 'http://132.236.91.179:8008']
	Documents (2 instances): ['http://132.236.91.185:9003', 'http://132.236.91.185:9004']
	LLM (2 instances): ['http://132.236.91.186:8009', 'http://132.236.91.179:8010']
	Sentiment/Safety (2 instances): ['http://132.236.91.185:9005', 'http://132.236.91.185:9006']
============================================================
Worker 0 started!
Worker 1 started!

Starting Flask orchestrator on 0.0.0.0:9000
 * Serving Flask app 'pipeline'
 * Debug mode: off
[Orchestrator] Queueing request req_1765257679_0
[Orchestrator] Queueing request req_1765257679_1
[Orchestrator] Queueing request req_1765257679_2
[Orchestrator] Queueing request req_1765257679_3
[Orchestrator] Queueing request req_1765257679_4
[Orchestrator] Queueing request req_1765257679_5
[Orchestrator] Queueing request req_1765257679_6
[Orchestrator] Queueing request req_1765257679_7
[Orchestrator] Queueing request req_1765257679_8
[Orchestrator] Queueing request req_1765257679_9
[Orchestrator] Queueing request req_1765257679_10
[Orchestrator] Queueing request req_1765257679_11
[Orchestrator] Queueing request req_1765257679_12
[Orchestrator] Queueing request req_1765257679_13
[Orchestrator] Queueing request req_1765257680_14
Processing batch of 8 requests.

[TIMING] process_pipeline - START

============================================================
Processing batch of 8 requests
============================================================
- req_1765257679_0: How do I return a defective product?...
- req_1765257679_2: My order hasn't arrived yet, tracking number is AB...
- req_1765257679_4: Is there a warranty on electronic items?...
[Orchestrator] Queueing request req_1765257680_15
Processing batch of 8 requests.- req_1765257679_6: What payment methods do you accept?...


[TIMING] process_pipeline - START
- req_1765257679_8: How do I return a defective product?...
- req_1765257679_10: My order hasn't arrived yet, tracking number is AB...
- req_1765257679_12: Is there a warranty on electronic items?...
- req_1765257680_14: What payment methods do you accept?...
[Step 1/5] Calling embedding service at http://132.236.91.185:9001...
[Orchestrator] Queueing request req_1765257680_16

============================================================
Processing batch of 8 requests
============================================================
- req_1765257679_1: What is your refund policy?...
- req_1765257679_3: How do I update my billing information?...
- req_1765257679_5: Can I change my shipping address after placing an ...
- req_1765257679_7: How long does shipping typically take?...
- req_1765257679_9: What is your refund policy?...
- req_1765257679_11: How do I update my billing information?...
- req_1765257679_13: Can I change my shipping address after placing an ...
- req_1765257680_15: How long does shipping typically take?...
[Step 1/5] Calling embedding service at http://132.236.91.185:9002...
[Orchestrator] Queueing request req_1765257680_17
[Orchestrator] Queueing request req_1765257680_18
[Orchestrator] Queueing request req_1765257680_19
[Step 2/5] Calling FAISS service at http://132.236.91.186:8007...
[Step 2/5] Calling FAISS service at http://132.236.91.179:8008...
[Step 3/5] Calling documents service at http://132.236.91.185:9003...
[Step 4/5] Calling LLM service at http://132.236.91.186:8009...
[Step 3/5] Calling documents service at http://132.236.91.185:9004...
[Step 4/5] Calling LLM service at http://132.236.91.179:8010...
[Step 5/5] Calling sentiment/safety service at http://132.236.91.185:9005...
Request req_1765257679_1 processed in 85.11 seconds
Request req_1765257679_3 processed in 85.11 seconds
Request req_1765257679_5 processed in 85.11 seconds
Request req_1765257679_7 processed in 85.11 seconds
Request req_1765257679_9 processed in 85.11 seconds
Request req_1765257679_11 processed in 85.11 seconds
Request req_1765257679_13 processed in 85.11 seconds
Request req_1765257680_15 processed in 85.11 seconds
Filename: /home/rb972/cs5416-final-project/exp3/pipeline.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    81    502.8 MiB    502.8 MiB           1   @profile_with_timing
    82                                         @profile
    83                                         def process_pipeline(reqs: list[PipelineRequest]) -> list[PipelineResponse]:
    84                                             """
    85                                             Orchestrate the full pipeline through microservices
    86                                             """
    87                                         
    88    502.8 MiB      0.0 MiB           1       batch_size = len(reqs)
    89    502.8 MiB      0.0 MiB          11       start_times = [time.time() for _ in reqs]
    90    503.1 MiB      0.4 MiB          11       queries = [req.query for req in reqs]
    91                                         
    92    503.1 MiB      0.0 MiB           1       print("\n" + "=" * 60, flush=True)
    93    503.1 MiB      0.0 MiB           1       print(f"Processing batch of {batch_size} requests", flush=True)
    94    503.1 MiB      0.0 MiB           1       print("=" * 60, flush=True)
    95    503.1 MiB      0.0 MiB           9       for req in reqs:
    96    503.1 MiB      0.0 MiB           8           print(f"- {req.request_id}: {req.query[:50]}...", flush=True)
    97                                         
    98    503.1 MiB      0.0 MiB           1       try:
    99                                                 # Step 1: Generate embeddings
   100    503.1 MiB      0.0 MiB           1           embedding_url = get_service_url("embedding", EMBEDDING_SERVICE_URLS)
   101    503.1 MiB      0.0 MiB           1           print(f"[Step 1/5] Calling embedding service at {embedding_url}...", flush=True)
   102    503.7 MiB      0.5 MiB           2           response = requests.post(
   103    503.1 MiB      0.0 MiB           1               f"{embedding_url}/process", json={"texts": queries}, timeout=1000
   104                                                 )
   105    504.2 MiB      0.5 MiB           1           response.raise_for_status()
   106    504.4 MiB      0.3 MiB           1           embeddings = response.json()["embeddings"]
   107                                         
   108                                                 # Step 2: FAISS search
   109    504.4 MiB      0.0 MiB           1           faiss_url = get_service_url("faiss", FAISS_SERVICE_URLS)
   110    504.4 MiB      0.0 MiB           1           print(f"[Step 2/5] Calling FAISS service at {faiss_url}...", flush=True)
   111    505.2 MiB      0.3 MiB           2           response = requests.post(
   112    504.9 MiB      0.5 MiB           1               f"{faiss_url}/process", json={"embeddings": embeddings}, timeout=1000
   113                                                 )
   114    505.2 MiB      0.0 MiB           1           response.raise_for_status()
   115    505.2 MiB      0.0 MiB           1           doc_ids = response.json()["doc_ids"]
   116                                         
   117                                                 # Step 3: Fetch and rerank documents
   118    505.2 MiB      0.0 MiB           1           documents_url = get_service_url("documents", DOCUMENTS_SERVICE_URLS)
   119    505.2 MiB      0.0 MiB           1           print(f"[Step 3/5] Calling documents service at {documents_url}...", flush=True)
   120    505.2 MiB      0.0 MiB           2           response = requests.post(
   121    505.2 MiB      0.0 MiB           1               f"{documents_url}/process",
   122    505.2 MiB      0.0 MiB           1               json={"queries": queries, "doc_id_batches": doc_ids},
   123    505.2 MiB      0.0 MiB           1               timeout=1000,
   124                                                 )
   125    505.2 MiB      0.0 MiB           1           response.raise_for_status()
   126    505.2 MiB      0.0 MiB           1           reranked_documents = response.json()["reranked_documents"]
   127                                         
   128                                                 # Step 4: Generate LLM response
   129    505.2 MiB      0.0 MiB           1           llm_url = get_service_url("llm", LLM_SERVICE_URLS)
   130    505.2 MiB      0.0 MiB           1           print(f"[Step 4/5] Calling LLM service at {llm_url}...", flush=True)
   131    505.2 MiB      0.0 MiB           2           response = requests.post(
   132    505.2 MiB      0.0 MiB           1               f"{llm_url}/process",
   133    505.2 MiB      0.0 MiB           1               json={"queries": queries, "documents_batch": reranked_documents},
   134    505.2 MiB      0.0 MiB           1               timeout=1000,
   135                                                 )
   136    505.2 MiB      0.0 MiB           1           response.raise_for_status()
   137    505.2 MiB      0.0 MiB           1           llm_responses = response.json()["responses"]
   138                                         
   139                                                 # Step 5: Sentiment and safety analysis
   140    505.2 MiB      0.0 MiB           2           sentiment_url = get_service_url(
   141    505.2 MiB      0.0 MiB           1               "sentiment_safety", SENTIMENT_SAFETY_SERVICE_URLS
   142                                                 )
   143    505.2 MiB      0.0 MiB           2           print(
   144    505.2 MiB      0.0 MiB           1               f"[Step 5/5] Calling sentiment/safety service at {sentiment_url}...",
   145    505.2 MiB      0.0 MiB           1               flush=True,
   146                                                 )
   147    505.2 MiB      0.0 MiB           2           response = requests.post(
   148    505.2 MiB      0.0 MiB           1               f"{sentiment_url}/process",
   149    505.2 MiB      0.0 MiB           1               json={"texts": llm_responses},
   150    505.2 MiB      0.0 MiB           1               timeout=1000,
   151                                                 )
   152    505.2 MiB      0.0 MiB           1           response.raise_for_status()
   153    505.2 MiB      0.0 MiB           1           analysis = response.json()
   154    505.2 MiB      0.0 MiB           1           sentiments = analysis["sentiments"]
   155    505.2 MiB      0.0 MiB           1           toxicity_flags = analysis["toxicity_flags"]
   156                                         
   157    505.2 MiB      0.0 MiB           1           responses = []
   158    505.2 MiB      0.0 MiB           9           for idx, req in enumerate(reqs):
   159    505.2 MiB      0.0 MiB           8               processing_time = time.time() - start_times[idx]
   160    505.2 MiB      0.0 MiB          16               print(
   161    505.2 MiB      0.0 MiB           8                   f"Request {req.request_id} processed in {processing_time:.2f} seconds",
   162    505.2 MiB      0.0 MiB           8                   flush=True,
   163                                                     )
   164    505.2 MiB      0.0 MiB           8               sensitivity_result = "true" if toxicity_flags[idx] else "false"
   165    505.2 MiB      0.0 MiB          16               responses.append(
   166    505.2 MiB      0.0 MiB          16                   PipelineResponse(
   167    505.2 MiB      0.0 MiB           8                       request_id=req.request_id,
   168    505.2 MiB      0.0 MiB           8                       generated_response=llm_responses[idx],
   169    505.2 MiB      0.0 MiB           8                       sentiment=sentiments[idx],
   170    505.2 MiB      0.0 MiB           8                       is_toxic=sensitivity_result,
   171    505.2 MiB      0.0 MiB           8                       processing_time=processing_time,
   172                                                         )
   173                                                     )
   174                                         
   175    505.2 MiB      0.0 MiB           1           return responses
   176                                         
   177                                             except requests.exceptions.RequestException as e:
   178                                                 print(f"Batch processing failed: {e}", flush=True)
   179                                                 raise
   180                                             except Exception as e:
   181                                                 print(f"Batch processing error: {e}", flush=True)
   182                                                 raise


[TIMING] process_pipeline - END (took 85.12s)
Processing batch of 4 requests.

[TIMING] process_pipeline - START

============================================================
Processing batch of 4 requests
============================================================
- req_1765257680_16: How do I return a defective product?...
- req_1765257680_17: What is your refund policy?...
- req_1765257680_18: My order hasn't arrived yet, tracking number is AB...
- req_1765257680_19: How do I update my billing information?...
[Step 1/5] Calling embedding service at http://132.236.91.185:9001...
[Step 2/5] Calling FAISS service at http://132.236.91.186:8007...
[Step 5/5] Calling sentiment/safety service at http://132.236.91.185:9006...
[Step 3/5] Calling documents service at http://132.236.91.185:9003...
[Step 4/5] Calling LLM service at http://132.236.91.186:8009...
Request req_1765257679_0 processed in 98.12 seconds
Request req_1765257679_2 processed in 98.12 seconds
Request req_1765257679_4 processed in 98.12 seconds
Request req_1765257679_6 processed in 98.12 seconds
Request req_1765257679_8 processed in 98.12 seconds
Request req_1765257679_10 processed in 98.13 seconds
Request req_1765257679_12 processed in 98.13 seconds
Request req_1765257680_14 processed in 98.13 seconds
Filename: /home/rb972/cs5416-final-project/exp3/pipeline.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    81    502.8 MiB    502.8 MiB           1   @profile_with_timing
    82                                         @profile
    83                                         def process_pipeline(reqs: list[PipelineRequest]) -> list[PipelineResponse]:
    84                                             """
    85                                             Orchestrate the full pipeline through microservices
    86                                             """
    87                                         
    88    502.8 MiB      0.0 MiB           1       batch_size = len(reqs)
    89    502.8 MiB      0.0 MiB          11       start_times = [time.time() for _ in reqs]
    90    502.8 MiB      0.0 MiB          11       queries = [req.query for req in reqs]
    91                                         
    92    502.8 MiB      0.0 MiB           1       print("\n" + "=" * 60, flush=True)
    93    502.8 MiB      0.0 MiB           1       print(f"Processing batch of {batch_size} requests", flush=True)
    94    502.8 MiB      0.0 MiB           1       print("=" * 60, flush=True)
    95    502.8 MiB      0.0 MiB           9       for req in reqs:
    96    502.8 MiB      0.0 MiB           8           print(f"- {req.request_id}: {req.query[:50]}...", flush=True)
    97                                         
    98    502.8 MiB      0.0 MiB           1       try:
    99                                                 # Step 1: Generate embeddings
   100    502.8 MiB      0.0 MiB           1           embedding_url = get_service_url("embedding", EMBEDDING_SERVICE_URLS)
   101    502.8 MiB      0.0 MiB           1           print(f"[Step 1/5] Calling embedding service at {embedding_url}...", flush=True)
   102    503.7 MiB      0.9 MiB           2           response = requests.post(
   103    502.8 MiB      0.0 MiB           1               f"{embedding_url}/process", json={"texts": queries}, timeout=1000
   104                                                 )
   105    503.7 MiB      0.0 MiB           1           response.raise_for_status()
   106    504.4 MiB      0.8 MiB           1           embeddings = response.json()["embeddings"]
   107                                         
   108                                                 # Step 2: FAISS search
   109    504.4 MiB      0.0 MiB           1           faiss_url = get_service_url("faiss", FAISS_SERVICE_URLS)
   110    504.4 MiB      0.0 MiB           1           print(f"[Step 2/5] Calling FAISS service at {faiss_url}...", flush=True)
   111    505.2 MiB      0.8 MiB           2           response = requests.post(
   112    504.4 MiB      0.0 MiB           1               f"{faiss_url}/process", json={"embeddings": embeddings}, timeout=1000
   113                                                 )
   114    505.2 MiB      0.0 MiB           1           response.raise_for_status()
   115    505.2 MiB      0.0 MiB           1           doc_ids = response.json()["doc_ids"]
   116                                         
   117                                                 # Step 3: Fetch and rerank documents
   118    505.2 MiB      0.0 MiB           1           documents_url = get_service_url("documents", DOCUMENTS_SERVICE_URLS)
   119    505.2 MiB      0.0 MiB           1           print(f"[Step 3/5] Calling documents service at {documents_url}...", flush=True)
   120    505.2 MiB      0.0 MiB           2           response = requests.post(
   121    505.2 MiB      0.0 MiB           1               f"{documents_url}/process",
   122    505.2 MiB      0.0 MiB           1               json={"queries": queries, "doc_id_batches": doc_ids},
   123    505.2 MiB      0.0 MiB           1               timeout=1000,
   124                                                 )
   125    505.2 MiB      0.0 MiB           1           response.raise_for_status()
   126    505.2 MiB      0.0 MiB           1           reranked_documents = response.json()["reranked_documents"]
   127                                         
   128                                                 # Step 4: Generate LLM response
   129    505.2 MiB      0.0 MiB           1           llm_url = get_service_url("llm", LLM_SERVICE_URLS)
   130    505.2 MiB      0.0 MiB           1           print(f"[Step 4/5] Calling LLM service at {llm_url}...", flush=True)
   131    505.8 MiB      0.6 MiB           2           response = requests.post(
   132    505.2 MiB      0.0 MiB           1               f"{llm_url}/process",
   133    505.2 MiB      0.0 MiB           1               json={"queries": queries, "documents_batch": reranked_documents},
   134    505.2 MiB      0.0 MiB           1               timeout=1000,
   135                                                 )
   136    505.8 MiB      0.0 MiB           1           response.raise_for_status()
   137    505.8 MiB      0.0 MiB           1           llm_responses = response.json()["responses"]
   138                                         
   139                                                 # Step 5: Sentiment and safety analysis
   140    505.8 MiB      0.0 MiB           2           sentiment_url = get_service_url(
   141    505.8 MiB      0.0 MiB           1               "sentiment_safety", SENTIMENT_SAFETY_SERVICE_URLS
   142                                                 )
   143    505.8 MiB      0.0 MiB           2           print(
   144    505.8 MiB      0.0 MiB           1               f"[Step 5/5] Calling sentiment/safety service at {sentiment_url}...",
   145    505.8 MiB      0.0 MiB           1               flush=True,
   146                                                 )
   147    505.8 MiB      0.0 MiB           2           response = requests.post(
   148    505.8 MiB      0.0 MiB           1               f"{sentiment_url}/process",
   149    505.8 MiB      0.0 MiB           1               json={"texts": llm_responses},
   150    505.8 MiB      0.0 MiB           1               timeout=1000,
   151                                                 )
   152    505.8 MiB      0.0 MiB           1           response.raise_for_status()
   153    505.8 MiB      0.0 MiB           1           analysis = response.json()
   154    505.8 MiB      0.0 MiB           1           sentiments = analysis["sentiments"]
   155    505.8 MiB      0.0 MiB           1           toxicity_flags = analysis["toxicity_flags"]
   156                                         
   157    505.8 MiB      0.0 MiB           1           responses = []
   158    505.8 MiB      0.0 MiB           9           for idx, req in enumerate(reqs):
   159    505.8 MiB      0.0 MiB           8               processing_time = time.time() - start_times[idx]
   160    505.8 MiB      0.0 MiB          16               print(
   161    505.8 MiB      0.0 MiB           8                   f"Request {req.request_id} processed in {processing_time:.2f} seconds",
   162    505.8 MiB      0.0 MiB           8                   flush=True,
   163                                                     )
   164    505.8 MiB      0.0 MiB           8               sensitivity_result = "true" if toxicity_flags[idx] else "false"
   165    505.8 MiB      0.0 MiB          16               responses.append(
   166    505.8 MiB      0.0 MiB          16                   PipelineResponse(
   167    505.8 MiB      0.0 MiB           8                       request_id=req.request_id,
   168    505.8 MiB      0.0 MiB           8                       generated_response=llm_responses[idx],
   169    505.8 MiB      0.0 MiB           8                       sentiment=sentiments[idx],
   170    505.8 MiB      0.0 MiB           8                       is_toxic=sensitivity_result,
   171    505.8 MiB      0.0 MiB           8                       processing_time=processing_time,
   172                                                         )
   173                                                     )
   174                                         
   175    505.8 MiB      0.0 MiB           1           return responses
   176                                         
   177                                             except requests.exceptions.RequestException as e:
   178                                                 print(f"Batch processing failed: {e}", flush=True)
   179                                                 raise
   180                                             except Exception as e:
   181                                                 print(f"Batch processing error: {e}", flush=True)
   182                                                 raise


[TIMING] process_pipeline - END (took 98.14s)
[Step 5/5] Calling sentiment/safety service at http://132.236.91.185:9005...
Request req_1765257680_16 processed in 45.26 seconds
Request req_1765257680_17 processed in 45.26 seconds
Request req_1765257680_18 processed in 45.26 seconds
Request req_1765257680_19 processed in 45.26 seconds
Filename: /home/rb972/cs5416-final-project/exp3/pipeline.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    81    505.6 MiB    505.6 MiB           1   @profile_with_timing
    82                                         @profile
    83                                         def process_pipeline(reqs: list[PipelineRequest]) -> list[PipelineResponse]:
    84                                             """
    85                                             Orchestrate the full pipeline through microservices
    86                                             """
    87                                         
    88    505.6 MiB      0.0 MiB           1       batch_size = len(reqs)
    89    505.6 MiB      0.0 MiB           7       start_times = [time.time() for _ in reqs]
    90    505.6 MiB      0.0 MiB           7       queries = [req.query for req in reqs]
    91                                         
    92    505.6 MiB      0.0 MiB           1       print("\n" + "=" * 60, flush=True)
    93    505.6 MiB      0.0 MiB           1       print(f"Processing batch of {batch_size} requests", flush=True)
    94    505.6 MiB      0.0 MiB           1       print("=" * 60, flush=True)
    95    505.6 MiB      0.0 MiB           5       for req in reqs:
    96    505.6 MiB      0.0 MiB           4           print(f"- {req.request_id}: {req.query[:50]}...", flush=True)
    97                                         
    98    505.6 MiB      0.0 MiB           1       try:
    99                                                 # Step 1: Generate embeddings
   100    505.6 MiB      0.0 MiB           1           embedding_url = get_service_url("embedding", EMBEDDING_SERVICE_URLS)
   101    505.6 MiB      0.0 MiB           1           print(f"[Step 1/5] Calling embedding service at {embedding_url}...", flush=True)
   102    505.6 MiB      0.0 MiB           2           response = requests.post(
   103    505.6 MiB      0.0 MiB           1               f"{embedding_url}/process", json={"texts": queries}, timeout=1000
   104                                                 )
   105    505.6 MiB      0.0 MiB           1           response.raise_for_status()
   106    505.6 MiB      0.0 MiB           1           embeddings = response.json()["embeddings"]
   107                                         
   108                                                 # Step 2: FAISS search
   109    505.6 MiB      0.0 MiB           1           faiss_url = get_service_url("faiss", FAISS_SERVICE_URLS)
   110    505.6 MiB      0.0 MiB           1           print(f"[Step 2/5] Calling FAISS service at {faiss_url}...", flush=True)
   111    505.8 MiB      0.3 MiB           2           response = requests.post(
   112    505.6 MiB      0.0 MiB           1               f"{faiss_url}/process", json={"embeddings": embeddings}, timeout=1000
   113                                                 )
   114    505.8 MiB      0.0 MiB           1           response.raise_for_status()
   115    505.8 MiB      0.0 MiB           1           doc_ids = response.json()["doc_ids"]
   116                                         
   117                                                 # Step 3: Fetch and rerank documents
   118    505.8 MiB      0.0 MiB           1           documents_url = get_service_url("documents", DOCUMENTS_SERVICE_URLS)
   119    505.8 MiB      0.0 MiB           1           print(f"[Step 3/5] Calling documents service at {documents_url}...", flush=True)
   120    505.8 MiB      0.0 MiB           2           response = requests.post(
   121    505.8 MiB      0.0 MiB           1               f"{documents_url}/process",
   122    505.8 MiB      0.0 MiB           1               json={"queries": queries, "doc_id_batches": doc_ids},
   123    505.8 MiB      0.0 MiB           1               timeout=1000,
   124                                                 )
   125    505.8 MiB      0.0 MiB           1           response.raise_for_status()
   126    505.8 MiB      0.0 MiB           1           reranked_documents = response.json()["reranked_documents"]
   127                                         
   128                                                 # Step 4: Generate LLM response
   129    505.8 MiB      0.0 MiB           1           llm_url = get_service_url("llm", LLM_SERVICE_URLS)
   130    505.8 MiB      0.0 MiB           1           print(f"[Step 4/5] Calling LLM service at {llm_url}...", flush=True)
   131    506.1 MiB      0.2 MiB           2           response = requests.post(
   132    505.8 MiB      0.0 MiB           1               f"{llm_url}/process",
   133    505.8 MiB      0.0 MiB           1               json={"queries": queries, "documents_batch": reranked_documents},
   134    505.8 MiB      0.0 MiB           1               timeout=1000,
   135                                                 )
   136    506.1 MiB      0.0 MiB           1           response.raise_for_status()
   137    506.1 MiB      0.0 MiB           1           llm_responses = response.json()["responses"]
   138                                         
   139                                                 # Step 5: Sentiment and safety analysis
   140    506.1 MiB      0.0 MiB           2           sentiment_url = get_service_url(
   141    506.1 MiB      0.0 MiB           1               "sentiment_safety", SENTIMENT_SAFETY_SERVICE_URLS
   142                                                 )
   143    506.1 MiB      0.0 MiB           2           print(
   144    506.1 MiB      0.0 MiB           1               f"[Step 5/5] Calling sentiment/safety service at {sentiment_url}...",
   145    506.1 MiB      0.0 MiB           1               flush=True,
   146                                                 )
   147    506.1 MiB      0.0 MiB           2           response = requests.post(
   148    506.1 MiB      0.0 MiB           1               f"{sentiment_url}/process",
   149    506.1 MiB      0.0 MiB           1               json={"texts": llm_responses},
   150    506.1 MiB      0.0 MiB           1               timeout=1000,
   151                                                 )
   152    506.1 MiB      0.0 MiB           1           response.raise_for_status()
   153    506.1 MiB      0.0 MiB           1           analysis = response.json()
   154    506.1 MiB      0.0 MiB           1           sentiments = analysis["sentiments"]
   155    506.1 MiB      0.0 MiB           1           toxicity_flags = analysis["toxicity_flags"]
   156                                         
   157    506.1 MiB      0.0 MiB           1           responses = []
   158    506.1 MiB      0.0 MiB           5           for idx, req in enumerate(reqs):
   159    506.1 MiB      0.0 MiB           4               processing_time = time.time() - start_times[idx]
   160    506.1 MiB      0.0 MiB           8               print(
   161    506.1 MiB      0.0 MiB           4                   f"Request {req.request_id} processed in {processing_time:.2f} seconds",
   162    506.1 MiB      0.0 MiB           4                   flush=True,
   163                                                     )
   164    506.1 MiB      0.0 MiB           4               sensitivity_result = "true" if toxicity_flags[idx] else "false"
   165    506.1 MiB      0.0 MiB           8               responses.append(
   166    506.1 MiB      0.0 MiB           8                   PipelineResponse(
   167    506.1 MiB      0.0 MiB           4                       request_id=req.request_id,
   168    506.1 MiB      0.0 MiB           4                       generated_response=llm_responses[idx],
   169    506.1 MiB      0.0 MiB           4                       sentiment=sentiments[idx],
   170    506.1 MiB      0.0 MiB           4                       is_toxic=sensitivity_result,
   171    506.1 MiB      0.0 MiB           4                       processing_time=processing_time,
   172                                                         )
   173                                                     )
   174                                         
   175    506.1 MiB      0.0 MiB           1           return responses
   176                                         
   177                                             except requests.exceptions.RequestException as e:
   178                                                 print(f"Batch processing failed: {e}", flush=True)
   179                                                 raise
   180                                             except Exception as e:
   181                                                 print(f"Batch processing error: {e}", flush=True)
   182                                                 raise


[TIMING] process_pipeline - END (took 45.27s)
