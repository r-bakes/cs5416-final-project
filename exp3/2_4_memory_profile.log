[CONFIG] GPU not available, using CPU
============================================================
MICROSERVICES ORCHESTRATOR
============================================================
Orchestrator Node: 0
Port: 9000

Service URLs:
	Embedding (2 instances): ['http://132.236.91.185:9001', 'http://132.236.91.185:9002']
	FAISS (2 instances): ['http://132.236.91.186:8007', 'http://132.236.91.179:8008']
	Documents (2 instances): ['http://132.236.91.185:9003', 'http://132.236.91.185:9004']
	LLM (2 instances): ['http://132.236.91.186:8009', 'http://132.236.91.179:8010']
	Sentiment/Safety (2 instances): ['http://132.236.91.185:9005', 'http://132.236.91.185:9006']
============================================================
Worker 0 started!
Worker 1 started!

Starting Flask orchestrator on 0.0.0.0:9000
 * Serving Flask app 'pipeline'
 * Debug mode: off
[Orchestrator] Queueing request req_1765255717_0
[Orchestrator] Queueing request req_1765255717_1
[Orchestrator] Queueing request req_1765255717_2
[Orchestrator] Queueing request req_1765255717_3
[Orchestrator] Queueing request req_1765255717_4
[Orchestrator] Queueing request req_1765255717_5
[Orchestrator] Queueing request req_1765255717_6
Processing batch of 4 requests.

[TIMING] process_pipeline - START

============================================================
Processing batch of 4 requests
============================================================
- req_1765255717_0: How do I return a defective product?...
- req_1765255717_2: My order hasn't arrived yet, tracking number is AB...
- req_1765255717_4: Is there a warranty on electronic items?...
- req_1765255717_6: What payment methods do you accept?...
[Step 1/5] Calling embedding service at http://132.236.91.185:9001...
[Orchestrator] Queueing request req_1765255717_7
Processing batch of 4 requests.

[TIMING] process_pipeline - START
[Orchestrator] Queueing request req_1765255718_8

============================================================
Processing batch of 4 requests
============================================================
- req_1765255717_1: What is your refund policy?...
- req_1765255717_3: How do I update my billing information?...
- req_1765255717_5: Can I change my shipping address after placing an ...
- req_1765255717_7: How long does shipping typically take?...
[Step 1/5] Calling embedding service at http://132.236.91.185:9002...
[Orchestrator] Queueing request req_1765255718_9
[Orchestrator] Queueing request req_1765255718_10
[Orchestrator] Queueing request req_1765255718_11
[Orchestrator] Queueing request req_1765255718_12
[Orchestrator] Queueing request req_1765255718_13
[Orchestrator] Queueing request req_1765255718_14
[Orchestrator] Queueing request req_1765255718_15
[Orchestrator] Queueing request req_1765255718_16
[Orchestrator] Queueing request req_1765255718_17
[Orchestrator] Queueing request req_1765255718_18
[Orchestrator] Queueing request req_1765255718_19
[Step 2/5] Calling FAISS service at http://132.236.91.186:8007...
[Step 2/5] Calling FAISS service at http://132.236.91.179:8008...
[Step 3/5] Calling documents service at http://132.236.91.185:9003...
[Step 4/5] Calling LLM service at http://132.236.91.186:8009...
[Step 5/5] Calling sentiment/safety service at http://132.236.91.185:9005...
Request req_1765255717_1 processed in 31.29 seconds
Request req_1765255717_3 processed in 31.29 seconds
Request req_1765255717_5 processed in 31.29 seconds
Request req_1765255717_7 processed in 31.29 seconds
Filename: /home/rb972/cs5416-final-project/exp3/pipeline.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    81    502.8 MiB    502.8 MiB           1   @profile_with_timing
    82                                         @profile
    83                                         def process_pipeline(reqs: list[PipelineRequest]) -> list[PipelineResponse]:
    84                                             """
    85                                             Orchestrate the full pipeline through microservices
    86                                             """
    87                                         
    88    502.8 MiB      0.0 MiB           1       batch_size = len(reqs)
    89    502.8 MiB      0.0 MiB           7       start_times = [time.time() for _ in reqs]
    90    502.8 MiB      0.0 MiB           7       queries = [req.query for req in reqs]
    91                                         
    92    502.8 MiB      0.0 MiB           1       print("\n" + "=" * 60, flush=True)
    93    502.8 MiB      0.0 MiB           1       print(f"Processing batch of {batch_size} requests", flush=True)
    94    502.8 MiB      0.0 MiB           1       print("=" * 60, flush=True)
    95    502.8 MiB      0.0 MiB           5       for req in reqs:
    96    502.8 MiB      0.0 MiB           4           print(f"- {req.request_id}: {req.query[:50]}...", flush=True)
    97                                         
    98    502.8 MiB      0.0 MiB           1       try:
    99                                                 # Step 1: Generate embeddings
   100    502.8 MiB      0.0 MiB           1           embedding_url = get_service_url("embedding", EMBEDDING_SERVICE_URLS)
   101    502.8 MiB      0.0 MiB           1           print(f"[Step 1/5] Calling embedding service at {embedding_url}...", flush=True)
   102    503.1 MiB      0.3 MiB           2           response = requests.post(
   103    502.8 MiB      0.0 MiB           1               f"{embedding_url}/process", json={"texts": queries}, timeout=200
   104                                                 )
   105    503.1 MiB      0.0 MiB           1           response.raise_for_status()
   106    503.4 MiB      0.3 MiB           1           embeddings = response.json()["embeddings"]
   107                                         
   108                                                 # Step 2: FAISS search
   109    503.4 MiB      0.0 MiB           1           faiss_url = get_service_url("faiss", FAISS_SERVICE_URLS)
   110    503.4 MiB      0.0 MiB           1           print(f"[Step 2/5] Calling FAISS service at {faiss_url}...", flush=True)
   111    504.4 MiB      1.0 MiB           2           response = requests.post(
   112    503.4 MiB      0.0 MiB           1               f"{faiss_url}/process", json={"embeddings": embeddings}, timeout=200
   113                                                 )
   114    504.4 MiB      0.0 MiB           1           response.raise_for_status()
   115    504.4 MiB      0.0 MiB           1           doc_ids = response.json()["doc_ids"]
   116                                         
   117                                                 # Step 3: Fetch and rerank documents
   118    504.4 MiB      0.0 MiB           1           documents_url = get_service_url("documents", DOCUMENTS_SERVICE_URLS)
   119    504.4 MiB      0.0 MiB           1           print(f"[Step 3/5] Calling documents service at {documents_url}...", flush=True)
   120    504.4 MiB      0.0 MiB           2           response = requests.post(
   121    504.4 MiB      0.0 MiB           1               f"{documents_url}/process",
   122    504.4 MiB      0.0 MiB           1               json={"queries": queries, "doc_id_batches": doc_ids},
   123    504.4 MiB      0.0 MiB           1               timeout=200,
   124                                                 )
   125    504.4 MiB      0.0 MiB           1           response.raise_for_status()
   126    504.4 MiB      0.0 MiB           1           reranked_documents = response.json()["reranked_documents"]
   127                                         
   128                                                 # Step 4: Generate LLM response
   129    504.4 MiB      0.0 MiB           1           llm_url = get_service_url("llm", LLM_SERVICE_URLS)
   130    504.4 MiB      0.0 MiB           1           print(f"[Step 4/5] Calling LLM service at {llm_url}...", flush=True)
   131    504.4 MiB      0.0 MiB           2           response = requests.post(
   132    504.4 MiB      0.0 MiB           1               f"{llm_url}/process",
   133    504.4 MiB      0.0 MiB           1               json={"queries": queries, "documents_batch": reranked_documents},
   134    504.4 MiB      0.0 MiB           1               timeout=200,
   135                                                 )
   136    504.4 MiB      0.0 MiB           1           response.raise_for_status()
   137    504.4 MiB      0.0 MiB           1           llm_responses = response.json()["responses"]
   138                                         
   139                                                 # Step 5: Sentiment and safety analysis
   140    504.4 MiB      0.0 MiB           2           sentiment_url = get_service_url(
   141    504.4 MiB      0.0 MiB           1               "sentiment_safety", SENTIMENT_SAFETY_SERVICE_URLS
   142                                                 )
   143    504.4 MiB      0.0 MiB           2           print(
   144    504.4 MiB      0.0 MiB           1               f"[Step 5/5] Calling sentiment/safety service at {sentiment_url}...",
   145    504.4 MiB      0.0 MiB           1               flush=True,
   146                                                 )
   147    504.4 MiB      0.0 MiB           2           response = requests.post(
   148    504.4 MiB      0.0 MiB           1               f"{sentiment_url}/process",
   149    504.4 MiB      0.0 MiB           1               json={"texts": llm_responses},
   150    504.4 MiB      0.0 MiB           1               timeout=200,
   151                                                 )
   152    504.4 MiB      0.0 MiB           1           response.raise_for_status()
   153    504.4 MiB      0.0 MiB           1           analysis = response.json()
   154    504.4 MiB      0.0 MiB           1           sentiments = analysis["sentiments"]
   155    504.4 MiB      0.0 MiB           1           toxicity_flags = analysis["toxicity_flags"]
   156                                         
   157    504.4 MiB      0.0 MiB           1           responses = []
   158    504.4 MiB      0.0 MiB           5           for idx, req in enumerate(reqs):
   159    504.4 MiB      0.0 MiB           4               processing_time = time.time() - start_times[idx]
   160    504.4 MiB      0.0 MiB           8               print(
   161    504.4 MiB      0.0 MiB           4                   f"Request {req.request_id} processed in {processing_time:.2f} seconds",
   162    504.4 MiB      0.0 MiB           4                   flush=True,
   163                                                     )
   164    504.4 MiB      0.0 MiB           4               sensitivity_result = "true" if toxicity_flags[idx] else "false"
   165    504.4 MiB      0.0 MiB           8               responses.append(
   166    504.4 MiB      0.0 MiB           8                   PipelineResponse(
   167    504.4 MiB      0.0 MiB           4                       request_id=req.request_id,
   168    504.4 MiB      0.0 MiB           4                       generated_response=llm_responses[idx],
   169    504.4 MiB      0.0 MiB           4                       sentiment=sentiments[idx],
   170    504.4 MiB      0.0 MiB           4                       is_toxic=sensitivity_result,
   171    504.4 MiB      0.0 MiB           4                       processing_time=processing_time,
   172                                                         )
   173                                                     )
   174                                         
   175    504.4 MiB      0.0 MiB           1           return responses
   176                                         
   177                                             except requests.exceptions.RequestException as e:
   178                                                 print(f"Batch processing failed: {e}", flush=True)
   179                                                 raise
   180                                             except Exception as e:
   181                                                 print(f"Batch processing error: {e}", flush=True)
   182                                                 raise


[TIMING] process_pipeline - END (took 31.30s)
Processing batch of 4 requests.

[TIMING] process_pipeline - START

============================================================
Processing batch of 4 requests
============================================================
- req_1765255718_8: How do I return a defective product?...
- req_1765255718_9: What is your refund policy?...
- req_1765255718_10: My order hasn't arrived yet, tracking number is AB...
- req_1765255718_11: How do I update my billing information?...
[Step 1/5] Calling embedding service at http://132.236.91.185:9001...
[Step 2/5] Calling FAISS service at http://132.236.91.186:8007...
[Step 3/5] Calling documents service at http://132.236.91.185:9004...
[Step 4/5] Calling LLM service at http://132.236.91.179:8010...
[Step 3/5] Calling documents service at http://132.236.91.185:9003...
[Step 4/5] Calling LLM service at http://132.236.91.186:8009...
[Step 5/5] Calling sentiment/safety service at http://132.236.91.185:9006...
Request req_1765255717_0 processed in 86.72 seconds
Request req_1765255717_2 processed in 86.72 seconds
Request req_1765255717_4 processed in 86.73 seconds
Request req_1765255717_6 processed in 86.73 seconds
Filename: /home/rb972/cs5416-final-project/exp3/pipeline.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    81    502.8 MiB    502.8 MiB           1   @profile_with_timing
    82                                         @profile
    83                                         def process_pipeline(reqs: list[PipelineRequest]) -> list[PipelineResponse]:
    84                                             """
    85                                             Orchestrate the full pipeline through microservices
    86                                             """
    87                                         
    88    502.8 MiB      0.0 MiB           1       batch_size = len(reqs)
    89    502.8 MiB      0.0 MiB           7       start_times = [time.time() for _ in reqs]
    90    502.8 MiB      0.0 MiB           7       queries = [req.query for req in reqs]
    91                                         
    92    502.8 MiB      0.0 MiB           1       print("\n" + "=" * 60, flush=True)
    93    502.8 MiB      0.0 MiB           1       print(f"Processing batch of {batch_size} requests", flush=True)
    94    502.8 MiB      0.0 MiB           1       print("=" * 60, flush=True)
    95    502.8 MiB      0.0 MiB           5       for req in reqs:
    96    502.8 MiB      0.0 MiB           4           print(f"- {req.request_id}: {req.query[:50]}...", flush=True)
    97                                         
    98    502.8 MiB      0.0 MiB           1       try:
    99                                                 # Step 1: Generate embeddings
   100    502.8 MiB      0.0 MiB           1           embedding_url = get_service_url("embedding", EMBEDDING_SERVICE_URLS)
   101    502.8 MiB      0.0 MiB           1           print(f"[Step 1/5] Calling embedding service at {embedding_url}...", flush=True)
   102    504.2 MiB      1.3 MiB           2           response = requests.post(
   103    502.8 MiB      0.0 MiB           1               f"{embedding_url}/process", json={"texts": queries}, timeout=200
   104                                                 )
   105    504.2 MiB      0.0 MiB           1           response.raise_for_status()
   106    504.2 MiB      0.0 MiB           1           embeddings = response.json()["embeddings"]
   107                                         
   108                                                 # Step 2: FAISS search
   109    504.2 MiB      0.0 MiB           1           faiss_url = get_service_url("faiss", FAISS_SERVICE_URLS)
   110    504.2 MiB      0.0 MiB           1           print(f"[Step 2/5] Calling FAISS service at {faiss_url}...", flush=True)
   111    504.7 MiB      0.5 MiB           2           response = requests.post(
   112    504.2 MiB      0.0 MiB           1               f"{faiss_url}/process", json={"embeddings": embeddings}, timeout=200
   113                                                 )
   114    504.7 MiB      0.0 MiB           1           response.raise_for_status()
   115    504.7 MiB      0.0 MiB           1           doc_ids = response.json()["doc_ids"]
   116                                         
   117                                                 # Step 3: Fetch and rerank documents
   118    504.7 MiB      0.0 MiB           1           documents_url = get_service_url("documents", DOCUMENTS_SERVICE_URLS)
   119    504.7 MiB      0.0 MiB           1           print(f"[Step 3/5] Calling documents service at {documents_url}...", flush=True)
   120    504.7 MiB      0.0 MiB           2           response = requests.post(
   121    504.7 MiB      0.0 MiB           1               f"{documents_url}/process",
   122    504.7 MiB      0.0 MiB           1               json={"queries": queries, "doc_id_batches": doc_ids},
   123    504.7 MiB      0.0 MiB           1               timeout=200,
   124                                                 )
   125    504.7 MiB      0.0 MiB           1           response.raise_for_status()
   126    504.7 MiB      0.0 MiB           1           reranked_documents = response.json()["reranked_documents"]
   127                                         
   128                                                 # Step 4: Generate LLM response
   129    504.7 MiB      0.0 MiB           1           llm_url = get_service_url("llm", LLM_SERVICE_URLS)
   130    504.7 MiB      0.0 MiB           1           print(f"[Step 4/5] Calling LLM service at {llm_url}...", flush=True)
   131    504.7 MiB      0.0 MiB           2           response = requests.post(
   132    504.7 MiB      0.0 MiB           1               f"{llm_url}/process",
   133    504.7 MiB      0.0 MiB           1               json={"queries": queries, "documents_batch": reranked_documents},
   134    504.7 MiB      0.0 MiB           1               timeout=200,
   135                                                 )
   136    504.7 MiB      0.0 MiB           1           response.raise_for_status()
   137    504.7 MiB      0.0 MiB           1           llm_responses = response.json()["responses"]
   138                                         
   139                                                 # Step 5: Sentiment and safety analysis
   140    504.7 MiB      0.0 MiB           2           sentiment_url = get_service_url(
   141    504.7 MiB      0.0 MiB           1               "sentiment_safety", SENTIMENT_SAFETY_SERVICE_URLS
   142                                                 )
   143    504.7 MiB      0.0 MiB           2           print(
   144    504.7 MiB      0.0 MiB           1               f"[Step 5/5] Calling sentiment/safety service at {sentiment_url}...",
   145    504.7 MiB      0.0 MiB           1               flush=True,
   146                                                 )
   147    504.7 MiB      0.0 MiB           2           response = requests.post(
   148    504.7 MiB      0.0 MiB           1               f"{sentiment_url}/process",
   149    504.7 MiB      0.0 MiB           1               json={"texts": llm_responses},
   150    504.7 MiB      0.0 MiB           1               timeout=200,
   151                                                 )
   152    504.7 MiB      0.0 MiB           1           response.raise_for_status()
   153    504.7 MiB      0.0 MiB           1           analysis = response.json()
   154    504.7 MiB      0.0 MiB           1           sentiments = analysis["sentiments"]
   155    504.7 MiB      0.0 MiB           1           toxicity_flags = analysis["toxicity_flags"]
   156                                         
   157    504.7 MiB      0.0 MiB           1           responses = []
   158    504.7 MiB      0.0 MiB           5           for idx, req in enumerate(reqs):
   159    504.7 MiB      0.0 MiB           4               processing_time = time.time() - start_times[idx]
   160    504.7 MiB      0.0 MiB           8               print(
   161    504.7 MiB      0.0 MiB           4                   f"Request {req.request_id} processed in {processing_time:.2f} seconds",
   162    504.7 MiB      0.0 MiB           4                   flush=True,
   163                                                     )
   164    504.7 MiB      0.0 MiB           4               sensitivity_result = "true" if toxicity_flags[idx] else "false"
   165    504.7 MiB      0.0 MiB           8               responses.append(
   166    504.7 MiB      0.0 MiB           8                   PipelineResponse(
   167    504.7 MiB      0.0 MiB           4                       request_id=req.request_id,
   168    504.7 MiB      0.0 MiB           4                       generated_response=llm_responses[idx],
   169    504.7 MiB      0.0 MiB           4                       sentiment=sentiments[idx],
   170    504.7 MiB      0.0 MiB           4                       is_toxic=sensitivity_result,
   171    504.7 MiB      0.0 MiB           4                       processing_time=processing_time,
   172                                                         )
   173                                                     )
   174                                         
   175    504.7 MiB      0.0 MiB           1           return responses
   176                                         
   177                                             except requests.exceptions.RequestException as e:
   178                                                 print(f"Batch processing failed: {e}", flush=True)
   179                                                 raise
   180                                             except Exception as e:
   181                                                 print(f"Batch processing error: {e}", flush=True)
   182                                                 raise


[TIMING] process_pipeline - END (took 86.73s)
Processing batch of 4 requests.

[TIMING] process_pipeline - START

============================================================
Processing batch of 4 requests
============================================================
- req_1765255718_12: Is there a warranty on electronic items?...
- req_1765255718_13: Can I change my shipping address after placing an ...
- req_1765255718_14: What payment methods do you accept?...
- req_1765255718_15: How long does shipping typically take?...
[Step 1/5] Calling embedding service at http://132.236.91.185:9002...
[Step 2/5] Calling FAISS service at http://132.236.91.179:8008...
[Step 5/5] Calling sentiment/safety service at http://132.236.91.185:9005...
Request req_1765255718_8 processed in 80.18 seconds
Request req_1765255718_9 processed in 80.19 seconds
Request req_1765255718_10 processed in 80.19 seconds
Request req_1765255718_11 processed in 80.19 seconds
Filename: /home/rb972/cs5416-final-project/exp3/pipeline.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    81    504.4 MiB    504.4 MiB           1   @profile_with_timing
    82                                         @profile
    83                                         def process_pipeline(reqs: list[PipelineRequest]) -> list[PipelineResponse]:
    84                                             """
    85                                             Orchestrate the full pipeline through microservices
    86                                             """
    87                                         
    88    504.4 MiB      0.0 MiB           1       batch_size = len(reqs)
    89    504.4 MiB      0.0 MiB           7       start_times = [time.time() for _ in reqs]
    90    504.4 MiB      0.0 MiB           7       queries = [req.query for req in reqs]
    91                                         
    92    504.4 MiB      0.0 MiB           1       print("\n" + "=" * 60, flush=True)
    93    504.4 MiB      0.0 MiB           1       print(f"Processing batch of {batch_size} requests", flush=True)
    94    504.4 MiB      0.0 MiB           1       print("=" * 60, flush=True)
    95    504.4 MiB      0.0 MiB           5       for req in reqs:
    96    504.4 MiB      0.0 MiB           4           print(f"- {req.request_id}: {req.query[:50]}...", flush=True)
    97                                         
    98    504.4 MiB      0.0 MiB           1       try:
    99                                                 # Step 1: Generate embeddings
   100    504.4 MiB      0.0 MiB           1           embedding_url = get_service_url("embedding", EMBEDDING_SERVICE_URLS)
   101    504.4 MiB      0.0 MiB           1           print(f"[Step 1/5] Calling embedding service at {embedding_url}...", flush=True)
   102    504.7 MiB      0.2 MiB           2           response = requests.post(
   103    504.4 MiB      0.0 MiB           1               f"{embedding_url}/process", json={"texts": queries}, timeout=200
   104                                                 )
   105    504.7 MiB      0.0 MiB           1           response.raise_for_status()
   106    504.7 MiB      0.0 MiB           1           embeddings = response.json()["embeddings"]
   107                                         
   108                                                 # Step 2: FAISS search
   109    504.7 MiB      0.0 MiB           1           faiss_url = get_service_url("faiss", FAISS_SERVICE_URLS)
   110    504.7 MiB      0.0 MiB           1           print(f"[Step 2/5] Calling FAISS service at {faiss_url}...", flush=True)
   111    504.7 MiB      0.0 MiB           2           response = requests.post(
   112    504.7 MiB      0.0 MiB           1               f"{faiss_url}/process", json={"embeddings": embeddings}, timeout=200
   113                                                 )
   114    504.7 MiB      0.0 MiB           1           response.raise_for_status()
   115    504.7 MiB      0.0 MiB           1           doc_ids = response.json()["doc_ids"]
   116                                         
   117                                                 # Step 3: Fetch and rerank documents
   118    504.7 MiB      0.0 MiB           1           documents_url = get_service_url("documents", DOCUMENTS_SERVICE_URLS)
   119    504.7 MiB      0.0 MiB           1           print(f"[Step 3/5] Calling documents service at {documents_url}...", flush=True)
   120    504.7 MiB      0.0 MiB           2           response = requests.post(
   121    504.7 MiB      0.0 MiB           1               f"{documents_url}/process",
   122    504.7 MiB      0.0 MiB           1               json={"queries": queries, "doc_id_batches": doc_ids},
   123    504.7 MiB      0.0 MiB           1               timeout=200,
   124                                                 )
   125    504.7 MiB      0.0 MiB           1           response.raise_for_status()
   126    504.7 MiB      0.0 MiB           1           reranked_documents = response.json()["reranked_documents"]
   127                                         
   128                                                 # Step 4: Generate LLM response
   129    504.7 MiB      0.0 MiB           1           llm_url = get_service_url("llm", LLM_SERVICE_URLS)
   130    504.7 MiB      0.0 MiB           1           print(f"[Step 4/5] Calling LLM service at {llm_url}...", flush=True)
   131    504.8 MiB      0.1 MiB           2           response = requests.post(
   132    504.7 MiB      0.0 MiB           1               f"{llm_url}/process",
   133    504.7 MiB      0.0 MiB           1               json={"queries": queries, "documents_batch": reranked_documents},
   134    504.7 MiB      0.0 MiB           1               timeout=200,
   135                                                 )
   136    504.8 MiB      0.0 MiB           1           response.raise_for_status()
   137    504.8 MiB      0.0 MiB           1           llm_responses = response.json()["responses"]
   138                                         
   139                                                 # Step 5: Sentiment and safety analysis
   140    504.8 MiB      0.0 MiB           2           sentiment_url = get_service_url(
   141    504.8 MiB      0.0 MiB           1               "sentiment_safety", SENTIMENT_SAFETY_SERVICE_URLS
   142                                                 )
   143    504.8 MiB      0.0 MiB           2           print(
   144    504.8 MiB      0.0 MiB           1               f"[Step 5/5] Calling sentiment/safety service at {sentiment_url}...",
   145    504.8 MiB      0.0 MiB           1               flush=True,
   146                                                 )
   147    504.8 MiB      0.0 MiB           2           response = requests.post(
   148    504.8 MiB      0.0 MiB           1               f"{sentiment_url}/process",
   149    504.8 MiB      0.0 MiB           1               json={"texts": llm_responses},
   150    504.8 MiB      0.0 MiB           1               timeout=200,
   151                                                 )
   152    504.8 MiB      0.0 MiB           1           response.raise_for_status()
   153    504.8 MiB      0.0 MiB           1           analysis = response.json()
   154    504.8 MiB      0.0 MiB           1           sentiments = analysis["sentiments"]
   155    504.8 MiB      0.0 MiB           1           toxicity_flags = analysis["toxicity_flags"]
   156                                         
   157    504.8 MiB      0.0 MiB           1           responses = []
   158    504.8 MiB      0.0 MiB           5           for idx, req in enumerate(reqs):
   159    504.8 MiB      0.0 MiB           4               processing_time = time.time() - start_times[idx]
   160    504.8 MiB      0.0 MiB           8               print(
   161    504.8 MiB      0.0 MiB           4                   f"Request {req.request_id} processed in {processing_time:.2f} seconds",
   162    504.8 MiB      0.0 MiB           4                   flush=True,
   163                                                     )
   164    504.8 MiB      0.0 MiB           4               sensitivity_result = "true" if toxicity_flags[idx] else "false"
   165    504.8 MiB      0.0 MiB           8               responses.append(
   166    504.8 MiB      0.0 MiB           8                   PipelineResponse(
   167    504.8 MiB      0.0 MiB           4                       request_id=req.request_id,
   168    504.8 MiB      0.0 MiB           4                       generated_response=llm_responses[idx],
   169    504.8 MiB      0.0 MiB           4                       sentiment=sentiments[idx],
   170    504.8 MiB      0.0 MiB           4                       is_toxic=sensitivity_result,
   171    504.8 MiB      0.0 MiB           4                       processing_time=processing_time,
   172                                                         )
   173                                                     )
   174                                         
   175    504.8 MiB      0.0 MiB           1           return responses
   176                                         
   177                                             except requests.exceptions.RequestException as e:
   178                                                 print(f"Batch processing failed: {e}", flush=True)
   179                                                 raise
   180                                             except Exception as e:
   181                                                 print(f"Batch processing error: {e}", flush=True)
   182                                                 raise


[TIMING] process_pipeline - END (took 80.19s)
Processing batch of 4 requests.

[TIMING] process_pipeline - START

============================================================
Processing batch of 4 requests
============================================================
- req_1765255718_16: How do I return a defective product?...
- req_1765255718_17: What is your refund policy?...
- req_1765255718_18: My order hasn't arrived yet, tracking number is AB...
- req_1765255718_19: How do I update my billing information?...
[Step 1/5] Calling embedding service at http://132.236.91.185:9001...
[Step 2/5] Calling FAISS service at http://132.236.91.186:8007...
[Step 3/5] Calling documents service at http://132.236.91.185:9004...
[Step 4/5] Calling LLM service at http://132.236.91.179:8010...
[Step 5/5] Calling sentiment/safety service at http://132.236.91.185:9006...
Request req_1765255718_16 processed in 51.54 seconds
Request req_1765255718_17 processed in 51.54 seconds
Request req_1765255718_18 processed in 51.54 seconds
Request req_1765255718_19 processed in 51.54 seconds
Filename: /home/rb972/cs5416-final-project/exp3/pipeline.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    81    504.8 MiB    504.8 MiB           1   @profile_with_timing
    82                                         @profile
    83                                         def process_pipeline(reqs: list[PipelineRequest]) -> list[PipelineResponse]:
    84                                             """
    85                                             Orchestrate the full pipeline through microservices
    86                                             """
    87                                         
    88    504.8 MiB      0.0 MiB           1       batch_size = len(reqs)
    89    504.8 MiB      0.0 MiB           7       start_times = [time.time() for _ in reqs]
    90    504.8 MiB      0.0 MiB           7       queries = [req.query for req in reqs]
    91                                         
    92    504.8 MiB      0.0 MiB           1       print("\n" + "=" * 60, flush=True)
    93    504.8 MiB      0.0 MiB           1       print(f"Processing batch of {batch_size} requests", flush=True)
    94    504.8 MiB      0.0 MiB           1       print("=" * 60, flush=True)
    95    504.8 MiB      0.0 MiB           5       for req in reqs:
    96    504.8 MiB      0.0 MiB           4           print(f"- {req.request_id}: {req.query[:50]}...", flush=True)
    97                                         
    98    504.8 MiB      0.0 MiB           1       try:
    99                                                 # Step 1: Generate embeddings
   100    504.8 MiB      0.0 MiB           1           embedding_url = get_service_url("embedding", EMBEDDING_SERVICE_URLS)
   101    504.8 MiB      0.0 MiB           1           print(f"[Step 1/5] Calling embedding service at {embedding_url}...", flush=True)
   102    504.9 MiB      0.1 MiB           2           response = requests.post(
   103    504.8 MiB      0.0 MiB           1               f"{embedding_url}/process", json={"texts": queries}, timeout=200
   104                                                 )
   105    504.9 MiB      0.0 MiB           1           response.raise_for_status()
   106    504.9 MiB      0.0 MiB           1           embeddings = response.json()["embeddings"]
   107                                         
   108                                                 # Step 2: FAISS search
   109    504.9 MiB      0.0 MiB           1           faiss_url = get_service_url("faiss", FAISS_SERVICE_URLS)
   110    504.9 MiB      0.0 MiB           1           print(f"[Step 2/5] Calling FAISS service at {faiss_url}...", flush=True)
   111    504.9 MiB      0.0 MiB           2           response = requests.post(
   112    504.9 MiB      0.0 MiB           1               f"{faiss_url}/process", json={"embeddings": embeddings}, timeout=200
   113                                                 )
   114    504.9 MiB      0.0 MiB           1           response.raise_for_status()
   115    504.9 MiB      0.0 MiB           1           doc_ids = response.json()["doc_ids"]
   116                                         
   117                                                 # Step 3: Fetch and rerank documents
   118    504.9 MiB      0.0 MiB           1           documents_url = get_service_url("documents", DOCUMENTS_SERVICE_URLS)
   119    504.9 MiB      0.0 MiB           1           print(f"[Step 3/5] Calling documents service at {documents_url}...", flush=True)
   120    504.9 MiB      0.0 MiB           2           response = requests.post(
   121    504.9 MiB      0.0 MiB           1               f"{documents_url}/process",
   122    504.9 MiB      0.0 MiB           1               json={"queries": queries, "doc_id_batches": doc_ids},
   123    504.9 MiB      0.0 MiB           1               timeout=200,
   124                                                 )
   125    504.9 MiB      0.0 MiB           1           response.raise_for_status()
   126    504.9 MiB      0.0 MiB           1           reranked_documents = response.json()["reranked_documents"]
   127                                         
   128                                                 # Step 4: Generate LLM response
   129    504.9 MiB      0.0 MiB           1           llm_url = get_service_url("llm", LLM_SERVICE_URLS)
   130    504.9 MiB      0.0 MiB           1           print(f"[Step 4/5] Calling LLM service at {llm_url}...", flush=True)
   131    504.9 MiB      0.0 MiB           2           response = requests.post(
   132    504.9 MiB      0.0 MiB           1               f"{llm_url}/process",
   133    504.9 MiB      0.0 MiB           1               json={"queries": queries, "documents_batch": reranked_documents},
   134    504.9 MiB      0.0 MiB           1               timeout=200,
   135                                                 )
   136    504.9 MiB      0.0 MiB           1           response.raise_for_status()
   137    504.9 MiB      0.0 MiB           1           llm_responses = response.json()["responses"]
   138                                         
   139                                                 # Step 5: Sentiment and safety analysis
   140    504.9 MiB      0.0 MiB           2           sentiment_url = get_service_url(
   141    504.9 MiB      0.0 MiB           1               "sentiment_safety", SENTIMENT_SAFETY_SERVICE_URLS
   142                                                 )
   143    504.9 MiB      0.0 MiB           2           print(
   144    504.9 MiB      0.0 MiB           1               f"[Step 5/5] Calling sentiment/safety service at {sentiment_url}...",
   145    504.9 MiB      0.0 MiB           1               flush=True,
   146                                                 )
   147    504.9 MiB      0.0 MiB           2           response = requests.post(
   148    504.9 MiB      0.0 MiB           1               f"{sentiment_url}/process",
   149    504.9 MiB      0.0 MiB           1               json={"texts": llm_responses},
   150    504.9 MiB      0.0 MiB           1               timeout=200,
   151                                                 )
   152    504.9 MiB      0.0 MiB           1           response.raise_for_status()
   153    504.9 MiB      0.0 MiB           1           analysis = response.json()
   154    504.9 MiB      0.0 MiB           1           sentiments = analysis["sentiments"]
   155    504.9 MiB      0.0 MiB           1           toxicity_flags = analysis["toxicity_flags"]
   156                                         
   157    504.9 MiB      0.0 MiB           1           responses = []
   158    504.9 MiB      0.0 MiB           5           for idx, req in enumerate(reqs):
   159    504.9 MiB      0.0 MiB           4               processing_time = time.time() - start_times[idx]
   160    504.9 MiB      0.0 MiB           8               print(
   161    504.9 MiB      0.0 MiB           4                   f"Request {req.request_id} processed in {processing_time:.2f} seconds",
   162    504.9 MiB      0.0 MiB           4                   flush=True,
   163                                                     )
   164    504.9 MiB      0.0 MiB           4               sensitivity_result = "true" if toxicity_flags[idx] else "false"
   165    504.9 MiB      0.0 MiB           8               responses.append(
   166    504.9 MiB      0.0 MiB           8                   PipelineResponse(
   167    504.9 MiB      0.0 MiB           4                       request_id=req.request_id,
   168    504.9 MiB      0.0 MiB           4                       generated_response=llm_responses[idx],
   169    504.9 MiB      0.0 MiB           4                       sentiment=sentiments[idx],
   170    504.9 MiB      0.0 MiB           4                       is_toxic=sensitivity_result,
   171    504.9 MiB      0.0 MiB           4                       processing_time=processing_time,
   172                                                         )
   173                                                     )
   174                                         
   175    504.9 MiB      0.0 MiB           1           return responses
   176                                         
   177                                             except requests.exceptions.RequestException as e:
   178                                                 print(f"Batch processing failed: {e}", flush=True)
   179                                                 raise
   180                                             except Exception as e:
   181                                                 print(f"Batch processing error: {e}", flush=True)
   182                                                 raise


[TIMING] process_pipeline - END (took 51.54s)
[Step 3/5] Calling documents service at http://132.236.91.185:9003...
[Step 4/5] Calling LLM service at http://132.236.91.186:8009...
[Step 5/5] Calling sentiment/safety service at http://132.236.91.185:9005...
Request req_1765255718_12 processed in 114.69 seconds
Request req_1765255718_13 processed in 114.69 seconds
Request req_1765255718_14 processed in 114.69 seconds
Request req_1765255718_15 processed in 114.69 seconds
Filename: /home/rb972/cs5416-final-project/exp3/pipeline.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    81    504.7 MiB    504.7 MiB           1   @profile_with_timing
    82                                         @profile
    83                                         def process_pipeline(reqs: list[PipelineRequest]) -> list[PipelineResponse]:
    84                                             """
    85                                             Orchestrate the full pipeline through microservices
    86                                             """
    87                                         
    88    504.7 MiB      0.0 MiB           1       batch_size = len(reqs)
    89    504.7 MiB      0.0 MiB           7       start_times = [time.time() for _ in reqs]
    90    504.7 MiB     -0.1 MiB           7       queries = [req.query for req in reqs]
    91                                         
    92    504.7 MiB     -0.0 MiB           1       print("\n" + "=" * 60, flush=True)
    93    504.7 MiB      0.0 MiB           1       print(f"Processing batch of {batch_size} requests", flush=True)
    94    504.7 MiB      0.0 MiB           1       print("=" * 60, flush=True)
    95    504.7 MiB      0.0 MiB           5       for req in reqs:
    96    504.7 MiB      0.0 MiB           4           print(f"- {req.request_id}: {req.query[:50]}...", flush=True)
    97                                         
    98    504.7 MiB      0.0 MiB           1       try:
    99                                                 # Step 1: Generate embeddings
   100    504.7 MiB      0.0 MiB           1           embedding_url = get_service_url("embedding", EMBEDDING_SERVICE_URLS)
   101    504.7 MiB      0.0 MiB           1           print(f"[Step 1/5] Calling embedding service at {embedding_url}...", flush=True)
   102    504.8 MiB      0.1 MiB           2           response = requests.post(
   103    504.7 MiB      0.0 MiB           1               f"{embedding_url}/process", json={"texts": queries}, timeout=200
   104                                                 )
   105    504.8 MiB      0.0 MiB           1           response.raise_for_status()
   106    504.8 MiB      0.0 MiB           1           embeddings = response.json()["embeddings"]
   107                                         
   108                                                 # Step 2: FAISS search
   109    504.8 MiB      0.0 MiB           1           faiss_url = get_service_url("faiss", FAISS_SERVICE_URLS)
   110    504.8 MiB      0.0 MiB           1           print(f"[Step 2/5] Calling FAISS service at {faiss_url}...", flush=True)
   111    505.0 MiB      0.3 MiB           2           response = requests.post(
   112    504.8 MiB      0.0 MiB           1               f"{faiss_url}/process", json={"embeddings": embeddings}, timeout=200
   113                                                 )
   114    505.0 MiB      0.0 MiB           1           response.raise_for_status()
   115    505.0 MiB      0.0 MiB           1           doc_ids = response.json()["doc_ids"]
   116                                         
   117                                                 # Step 3: Fetch and rerank documents
   118    505.0 MiB      0.0 MiB           1           documents_url = get_service_url("documents", DOCUMENTS_SERVICE_URLS)
   119    505.0 MiB      0.0 MiB           1           print(f"[Step 3/5] Calling documents service at {documents_url}...", flush=True)
   120    505.0 MiB      0.0 MiB           2           response = requests.post(
   121    505.0 MiB      0.0 MiB           1               f"{documents_url}/process",
   122    505.0 MiB      0.0 MiB           1               json={"queries": queries, "doc_id_batches": doc_ids},
   123    505.0 MiB      0.0 MiB           1               timeout=200,
   124                                                 )
   125    505.0 MiB      0.0 MiB           1           response.raise_for_status()
   126    505.0 MiB      0.0 MiB           1           reranked_documents = response.json()["reranked_documents"]
   127                                         
   128                                                 # Step 4: Generate LLM response
   129    505.0 MiB      0.0 MiB           1           llm_url = get_service_url("llm", LLM_SERVICE_URLS)
   130    505.0 MiB      0.0 MiB           1           print(f"[Step 4/5] Calling LLM service at {llm_url}...", flush=True)
   131    505.0 MiB      0.0 MiB           2           response = requests.post(
   132    505.0 MiB      0.0 MiB           1               f"{llm_url}/process",
   133    505.0 MiB      0.0 MiB           1               json={"queries": queries, "documents_batch": reranked_documents},
   134    505.0 MiB      0.0 MiB           1               timeout=200,
   135                                                 )
   136    505.0 MiB      0.0 MiB           1           response.raise_for_status()
   137    505.0 MiB      0.0 MiB           1           llm_responses = response.json()["responses"]
   138                                         
   139                                                 # Step 5: Sentiment and safety analysis
   140    505.0 MiB      0.0 MiB           2           sentiment_url = get_service_url(
   141    505.0 MiB      0.0 MiB           1               "sentiment_safety", SENTIMENT_SAFETY_SERVICE_URLS
   142                                                 )
   143    505.0 MiB      0.0 MiB           2           print(
   144    505.0 MiB      0.0 MiB           1               f"[Step 5/5] Calling sentiment/safety service at {sentiment_url}...",
   145    505.0 MiB      0.0 MiB           1               flush=True,
   146                                                 )
   147    505.0 MiB      0.0 MiB           2           response = requests.post(
   148    505.0 MiB      0.0 MiB           1               f"{sentiment_url}/process",
   149    505.0 MiB      0.0 MiB           1               json={"texts": llm_responses},
   150    505.0 MiB      0.0 MiB           1               timeout=200,
   151                                                 )
   152    505.0 MiB      0.0 MiB           1           response.raise_for_status()
   153    505.0 MiB      0.0 MiB           1           analysis = response.json()
   154    505.0 MiB      0.0 MiB           1           sentiments = analysis["sentiments"]
   155    505.0 MiB      0.0 MiB           1           toxicity_flags = analysis["toxicity_flags"]
   156                                         
   157    505.0 MiB      0.0 MiB           1           responses = []
   158    505.0 MiB      0.0 MiB           5           for idx, req in enumerate(reqs):
   159    505.0 MiB      0.0 MiB           4               processing_time = time.time() - start_times[idx]
   160    505.0 MiB      0.0 MiB           8               print(
   161    505.0 MiB      0.0 MiB           4                   f"Request {req.request_id} processed in {processing_time:.2f} seconds",
   162    505.0 MiB      0.0 MiB           4                   flush=True,
   163                                                     )
   164    505.0 MiB      0.0 MiB           4               sensitivity_result = "true" if toxicity_flags[idx] else "false"
   165    505.0 MiB      0.0 MiB           8               responses.append(
   166    505.0 MiB      0.0 MiB           8                   PipelineResponse(
   167    505.0 MiB      0.0 MiB           4                       request_id=req.request_id,
   168    505.0 MiB      0.0 MiB           4                       generated_response=llm_responses[idx],
   169    505.0 MiB      0.0 MiB           4                       sentiment=sentiments[idx],
   170    505.0 MiB      0.0 MiB           4                       is_toxic=sensitivity_result,
   171    505.0 MiB      0.0 MiB           4                       processing_time=processing_time,
   172                                                         )
   173                                                     )
   174                                         
   175    505.0 MiB      0.0 MiB           1           return responses
   176                                         
   177                                             except requests.exceptions.RequestException as e:
   178                                                 print(f"Batch processing failed: {e}", flush=True)
   179                                                 raise
   180                                             except Exception as e:
   181                                                 print(f"Batch processing error: {e}", flush=True)
   182                                                 raise


[TIMING] process_pipeline - END (took 114.69s)
