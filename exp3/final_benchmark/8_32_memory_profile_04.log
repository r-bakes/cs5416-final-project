[CONFIG] GPU not available, using CPU
============================================================
DOCUMENTS SERVICE (Fetch + Rerank)
============================================================
Node: 0
Port: 9004
DB: ../documents//documents.db
Reranker: BAAI/bge-reranker-base
Device: cpu
============================================================
 * Serving Flask app '03_documents_service'
 * Debug mode: off

[TIMING] _fetch_documents_batch - START

[TIMING] _fetch_documents_batch - START
Filename: /home/rb972/cs5416-final-project/exp3/03_documents_service.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    32   1062.6 MiB   1062.6 MiB           1   @profile_with_timing
    33                                         @profile
    34                                         def _fetch_documents_batch(doc_id_batches: list[list[int]]) -> list[list[dict]]:
    35                                             """Step 4: Fetch documents for each query in the batch using SQLite"""
    36   1062.6 MiB      0.0 MiB           1       conn = sqlite3.connect(db_path)
    37   1062.6 MiB      0.0 MiB           1       cursor = conn.cursor()
    38   1062.6 MiB      0.0 MiB           1       documents_batch = []
    39   1062.9 MiB      0.0 MiB          14       for doc_ids in doc_id_batches:
    40   1062.9 MiB      0.0 MiB          13           documents = []
    41   1062.9 MiB      0.0 MiB         143           for doc_id in doc_ids:
    42   1062.9 MiB      0.2 MiB         260               cursor.execute(
    43   1062.9 MiB      0.0 MiB         130                   "SELECT doc_id, title, content, category FROM documents WHERE doc_id = ?",
    44   1062.9 MiB      0.0 MiB         130                   (doc_id,),
    45                                                     )
    46   1062.9 MiB      0.0 MiB         130               result = cursor.fetchone()
    47   1062.9 MiB      0.0 MiB         130               if result:
    48   1062.9 MiB      0.0 MiB         260                   documents.append(
    49   1062.9 MiB      0.0 MiB         130                       {
    50   1062.9 MiB      0.0 MiB         130                           "doc_id": result[0],
    51   1062.9 MiB      0.0 MiB         130                           "title": result[1],
    52   1062.9 MiB      0.0 MiB         130                           "content": result[2],
    53   1062.9 MiB      0.0 MiB         130                           "category": result[3],
    54                                                             }
    55                                                         )
    56   1062.9 MiB      0.0 MiB          13           documents_batch.append(documents)
    57   1062.9 MiB      0.0 MiB           1       conn.close()
    58   1062.9 MiB      0.0 MiB           1       return documents_batch


[TIMING] _fetch_documents_batch - END (took 0.46s)

[TIMING] _rerank_documents_batch - START
Filename: /home/rb972/cs5416-final-project/exp3/03_documents_service.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    32   1062.6 MiB   1062.6 MiB           1   @profile_with_timing
    33                                         @profile
    34                                         def _fetch_documents_batch(doc_id_batches: list[list[int]]) -> list[list[dict]]:
    35                                             """Step 4: Fetch documents for each query in the batch using SQLite"""
    36   1062.6 MiB      0.0 MiB           1       conn = sqlite3.connect(db_path)
    37   1062.6 MiB      0.0 MiB           1       cursor = conn.cursor()
    38   1062.6 MiB      0.0 MiB           1       documents_batch = []
    39   1098.2 MiB      0.9 MiB          14       for doc_ids in doc_id_batches:
    40   1087.6 MiB      0.0 MiB          13           documents = []
    41   1096.4 MiB      0.8 MiB         143           for doc_id in doc_ids:
    42   1094.7 MiB     19.9 MiB         260               cursor.execute(
    43   1094.7 MiB      0.0 MiB         130                   "SELECT doc_id, title, content, category FROM documents WHERE doc_id = ?",
    44   1094.7 MiB      0.0 MiB         130                   (doc_id,),
    45                                                     )
    46   1094.7 MiB      7.9 MiB         130               result = cursor.fetchone()
    47   1094.7 MiB      0.0 MiB         130               if result:
    48   1095.6 MiB      3.3 MiB         260                   documents.append(
    49   1095.6 MiB      0.5 MiB         130                       {
    50   1094.7 MiB      0.7 MiB         130                           "doc_id": result[0],
    51   1094.7 MiB      0.0 MiB         130                           "title": result[1],
    52   1094.7 MiB      0.3 MiB         130                           "content": result[2],
    53   1095.1 MiB      0.4 MiB         130                           "category": result[3],
    54                                                             }
    55                                                         )
    56   1097.3 MiB      0.9 MiB          13           documents_batch.append(documents)
    57   1099.1 MiB      0.8 MiB           1       conn.close()
    58   1099.1 MiB      0.0 MiB           1       return documents_batch


[TIMING] _fetch_documents_batch - END (took 0.52s)

[TIMING] _rerank_documents_batch - START
Filename: /home/rb972/cs5416-final-project/exp3/03_documents_service.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    61   1062.9 MiB   1062.9 MiB           1   @profile_with_timing
    62                                         @profile
    63                                         def _rerank_documents_batch(
    64                                             queries: list[str], documents_batch: list[list[dict]]
    65                                         ) -> list[list[dict]]:
    66                                             """Step 5: Rerank retrieved documents for each query in the batch"""
    67   1062.9 MiB      0.0 MiB           1       reranked_batches = []
    68   1468.4 MiB      0.0 MiB          14       for query, documents in zip(queries, documents_batch):
    69   1468.4 MiB      0.0 MiB          13           if not documents:
    70                                                     reranked_batches.append([])
    71                                                     continue
    72   1468.4 MiB      0.0 MiB         169           pairs = [[query, doc["content"]] for doc in documents]
    73   1468.4 MiB      0.0 MiB          26           with torch.no_grad():
    74   1468.4 MiB      0.9 MiB          39               inputs = tokenizer(
    75   1468.4 MiB      0.0 MiB          13                   pairs,
    76   1468.4 MiB      0.0 MiB          13                   padding=True,
    77   1468.4 MiB      0.0 MiB          13                   truncation=True,
    78   1468.4 MiB      0.0 MiB          13                   return_tensors="pt",
    79   1468.4 MiB      0.0 MiB          13                   max_length=CONFIG["truncate_length"],
    80   1468.4 MiB      0.0 MiB          13               ).to(DEVICE)
    81   1468.4 MiB      0.0 MiB          13               scores = (
    82   1468.4 MiB    404.6 MiB          13                   model(**inputs, return_dict=True)
    83   1468.4 MiB      0.0 MiB          26                   .logits.view(
    84   1468.4 MiB      0.0 MiB          13                       -1,
    85                                                         )
    86   1468.4 MiB      0.0 MiB          13                   .float()
    87                                                     )
    88   1468.4 MiB      0.0 MiB          13           doc_scores = list(zip(documents, scores))
    89   1468.4 MiB      0.0 MiB         273           doc_scores.sort(key=lambda x: x[1], reverse=True)
    90   1468.4 MiB      0.0 MiB         169           reranked_batches.append([doc for doc, _ in doc_scores])
    91   1468.4 MiB      0.0 MiB           1       return reranked_batches


[TIMING] _rerank_documents_batch - END (took 22.57s)
Filename: /home/rb972/cs5416-final-project/exp3/03_documents_service.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    61   1099.1 MiB   1099.1 MiB           1   @profile_with_timing
    62                                         @profile
    63                                         def _rerank_documents_batch(
    64                                             queries: list[str], documents_batch: list[list[dict]]
    65                                         ) -> list[list[dict]]:
    66                                             """Step 5: Rerank retrieved documents for each query in the batch"""
    67   1099.1 MiB      0.0 MiB           1       reranked_batches = []
    68   1469.4 MiB      0.0 MiB          14       for query, documents in zip(queries, documents_batch):
    69   1469.4 MiB      0.0 MiB          13           if not documents:
    70                                                     reranked_batches.append([])
    71                                                     continue
    72   1469.4 MiB      0.0 MiB         169           pairs = [[query, doc["content"]] for doc in documents]
    73   1469.4 MiB      0.0 MiB          26           with torch.no_grad():
    74   1469.4 MiB      5.8 MiB          39               inputs = tokenizer(
    75   1469.4 MiB      0.0 MiB          13                   pairs,
    76   1469.4 MiB      0.0 MiB          13                   padding=True,
    77   1469.4 MiB      0.0 MiB          13                   truncation=True,
    78   1469.4 MiB      0.0 MiB          13                   return_tensors="pt",
    79   1469.4 MiB      0.0 MiB          13                   max_length=CONFIG["truncate_length"],
    80   1469.4 MiB      0.0 MiB          13               ).to(DEVICE)
    81   1469.4 MiB      0.0 MiB          13               scores = (
    82   1469.4 MiB    364.5 MiB          13                   model(**inputs, return_dict=True)
    83   1469.4 MiB      0.0 MiB          26                   .logits.view(
    84   1469.4 MiB      0.0 MiB          13                       -1,
    85                                                         )
    86   1469.4 MiB      0.0 MiB          13                   .float()
    87                                                     )
    88   1469.4 MiB      0.0 MiB          13           doc_scores = list(zip(documents, scores))
    89   1469.4 MiB      0.0 MiB         273           doc_scores.sort(key=lambda x: x[1], reverse=True)
    90   1469.4 MiB      0.0 MiB         169           reranked_batches.append([doc for doc, _ in doc_scores])
    91   1469.4 MiB      0.0 MiB           1       return reranked_batches


[TIMING] _rerank_documents_batch - END (took 26.57s)

[TIMING] _fetch_documents_batch - START
Filename: /home/rb972/cs5416-final-project/exp3/03_documents_service.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    32   1469.8 MiB   1469.8 MiB           1   @profile_with_timing
    33                                         @profile
    34                                         def _fetch_documents_batch(doc_id_batches: list[list[int]]) -> list[list[dict]]:
    35                                             """Step 4: Fetch documents for each query in the batch using SQLite"""
    36   1469.8 MiB      0.0 MiB           1       conn = sqlite3.connect(db_path)
    37   1469.8 MiB      0.0 MiB           1       cursor = conn.cursor()
    38   1469.8 MiB      0.0 MiB           1       documents_batch = []
    39   1469.8 MiB      0.0 MiB          13       for doc_ids in doc_id_batches:
    40   1469.8 MiB      0.0 MiB          12           documents = []
    41   1469.8 MiB      0.0 MiB         132           for doc_id in doc_ids:
    42   1469.8 MiB      0.0 MiB         240               cursor.execute(
    43   1469.8 MiB      0.0 MiB         120                   "SELECT doc_id, title, content, category FROM documents WHERE doc_id = ?",
    44   1469.8 MiB      0.0 MiB         120                   (doc_id,),
    45                                                     )
    46   1469.8 MiB      0.0 MiB         120               result = cursor.fetchone()
    47   1469.8 MiB      0.0 MiB         120               if result:
    48   1469.8 MiB      0.0 MiB         240                   documents.append(
    49   1469.8 MiB      0.0 MiB         120                       {
    50   1469.8 MiB      0.0 MiB         120                           "doc_id": result[0],
    51   1469.8 MiB      0.0 MiB         120                           "title": result[1],
    52   1469.8 MiB      0.0 MiB         120                           "content": result[2],
    53   1469.8 MiB      0.0 MiB         120                           "category": result[3],
    54                                                             }
    55                                                         )
    56   1469.8 MiB      0.0 MiB          12           documents_batch.append(documents)
    57   1469.8 MiB      0.0 MiB           1       conn.close()
    58   1469.8 MiB      0.0 MiB           1       return documents_batch


[TIMING] _fetch_documents_batch - END (took 0.40s)

[TIMING] _rerank_documents_batch - START

[TIMING] _fetch_documents_batch - START
Filename: /home/rb972/cs5416-final-project/exp3/03_documents_service.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    32   1469.8 MiB   1469.8 MiB           1   @profile_with_timing
    33                                         @profile
    34                                         def _fetch_documents_batch(doc_id_batches: list[list[int]]) -> list[list[dict]]:
    35                                             """Step 4: Fetch documents for each query in the batch using SQLite"""
    36   1469.8 MiB      0.0 MiB           1       conn = sqlite3.connect(db_path)
    37   1469.8 MiB      0.0 MiB           1       cursor = conn.cursor()
    38   1469.8 MiB      0.0 MiB           1       documents_batch = []
    39   1469.8 MiB      0.0 MiB          14       for doc_ids in doc_id_batches:
    40   1469.8 MiB      0.0 MiB          13           documents = []
    41   1469.8 MiB      0.0 MiB         143           for doc_id in doc_ids:
    42   1469.8 MiB      0.0 MiB         260               cursor.execute(
    43   1469.8 MiB      0.0 MiB         130                   "SELECT doc_id, title, content, category FROM documents WHERE doc_id = ?",
    44   1469.8 MiB      0.0 MiB         130                   (doc_id,),
    45                                                     )
    46   1469.8 MiB      0.0 MiB         130               result = cursor.fetchone()
    47   1469.8 MiB      0.0 MiB         130               if result:
    48   1469.8 MiB      0.0 MiB         260                   documents.append(
    49   1469.8 MiB      0.0 MiB         130                       {
    50   1469.8 MiB      0.0 MiB         130                           "doc_id": result[0],
    51   1469.8 MiB      0.0 MiB         130                           "title": result[1],
    52   1469.8 MiB      0.0 MiB         130                           "content": result[2],
    53   1469.8 MiB      0.0 MiB         130                           "category": result[3],
    54                                                             }
    55                                                         )
    56   1469.8 MiB      0.0 MiB          13           documents_batch.append(documents)
    57   1469.8 MiB      0.0 MiB           1       conn.close()
    58   1469.8 MiB      0.0 MiB           1       return documents_batch


[TIMING] _fetch_documents_batch - END (took 0.62s)

[TIMING] _rerank_documents_batch - START
Filename: /home/rb972/cs5416-final-project/exp3/03_documents_service.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    61   1469.8 MiB   1469.8 MiB           1   @profile_with_timing
    62                                         @profile
    63                                         def _rerank_documents_batch(
    64                                             queries: list[str], documents_batch: list[list[dict]]
    65                                         ) -> list[list[dict]]:
    66                                             """Step 5: Rerank retrieved documents for each query in the batch"""
    67   1469.8 MiB      0.0 MiB           1       reranked_batches = []
    68   1472.2 MiB      0.0 MiB          13       for query, documents in zip(queries, documents_batch):
    69   1472.2 MiB      0.0 MiB          12           if not documents:
    70                                                     reranked_batches.append([])
    71                                                     continue
    72   1472.2 MiB      0.0 MiB         156           pairs = [[query, doc["content"]] for doc in documents]
    73   1472.2 MiB      0.0 MiB          24           with torch.no_grad():
    74   1472.2 MiB      0.0 MiB          36               inputs = tokenizer(
    75   1472.2 MiB      0.0 MiB          12                   pairs,
    76   1472.2 MiB      0.0 MiB          12                   padding=True,
    77   1472.2 MiB      0.0 MiB          12                   truncation=True,
    78   1472.2 MiB      0.0 MiB          12                   return_tensors="pt",
    79   1472.2 MiB      0.0 MiB          12                   max_length=CONFIG["truncate_length"],
    80   1472.2 MiB      0.0 MiB          12               ).to(DEVICE)
    81   1472.2 MiB      0.0 MiB          12               scores = (
    82   1472.2 MiB      2.4 MiB          12                   model(**inputs, return_dict=True)
    83   1472.2 MiB      0.0 MiB          24                   .logits.view(
    84   1472.2 MiB      0.0 MiB          12                       -1,
    85                                                         )
    86   1472.2 MiB      0.0 MiB          12                   .float()
    87                                                     )
    88   1472.2 MiB      0.0 MiB          12           doc_scores = list(zip(documents, scores))
    89   1472.2 MiB      0.0 MiB         252           doc_scores.sort(key=lambda x: x[1], reverse=True)
    90   1472.2 MiB      0.0 MiB         156           reranked_batches.append([doc for doc, _ in doc_scores])
    91   1472.2 MiB      0.0 MiB           1       return reranked_batches


[TIMING] _rerank_documents_batch - END (took 21.84s)
Filename: /home/rb972/cs5416-final-project/exp3/03_documents_service.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    61   1469.8 MiB   1469.8 MiB           1   @profile_with_timing
    62                                         @profile
    63                                         def _rerank_documents_batch(
    64                                             queries: list[str], documents_batch: list[list[dict]]
    65                                         ) -> list[list[dict]]:
    66                                             """Step 5: Rerank retrieved documents for each query in the batch"""
    67   1469.8 MiB      0.0 MiB           1       reranked_batches = []
    68   1474.4 MiB      0.0 MiB          14       for query, documents in zip(queries, documents_batch):
    69   1472.2 MiB      0.0 MiB          13           if not documents:
    70                                                     reranked_batches.append([])
    71                                                     continue
    72   1472.2 MiB      0.0 MiB         169           pairs = [[query, doc["content"]] for doc in documents]
    73   1474.4 MiB      0.0 MiB          26           with torch.no_grad():
    74   1472.2 MiB      0.0 MiB          39               inputs = tokenizer(
    75   1472.2 MiB      0.0 MiB          13                   pairs,
    76   1472.2 MiB      0.0 MiB          13                   padding=True,
    77   1472.2 MiB      0.0 MiB          13                   truncation=True,
    78   1472.2 MiB      0.0 MiB          13                   return_tensors="pt",
    79   1472.2 MiB      0.0 MiB          13                   max_length=CONFIG["truncate_length"],
    80   1472.2 MiB      0.0 MiB          13               ).to(DEVICE)
    81   1474.4 MiB      0.0 MiB          13               scores = (
    82   1474.4 MiB      4.6 MiB          13                   model(**inputs, return_dict=True)
    83   1474.4 MiB      0.0 MiB          26                   .logits.view(
    84   1474.4 MiB      0.0 MiB          13                       -1,
    85                                                         )
    86   1474.4 MiB      0.0 MiB          13                   .float()
    87                                                     )
    88   1474.4 MiB      0.0 MiB          13           doc_scores = list(zip(documents, scores))
    89   1474.4 MiB      0.0 MiB         273           doc_scores.sort(key=lambda x: x[1], reverse=True)
    90   1474.4 MiB      0.0 MiB         169           reranked_batches.append([doc for doc, _ in doc_scores])
    91   1474.4 MiB      0.0 MiB           1       return reranked_batches


[TIMING] _rerank_documents_batch - END (took 22.13s)
